{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b615c1-1d04-4478-9dfa-ddd1022aa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from imgaug.augmentables.kps import KeypointsOnImage\n",
    "from imgaug.augmentables.kps import Keypoint\n",
    "import imgaug.augmenters as iaa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d064edaf-88bd-406e-8291-6b8683dc3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e11b3d-dad9-4f02-8683-47d4d399159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5414f5-3882-4a10-b98b-67868db26dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_KEYPOINTS = 16*2\n",
    "EPOCHS = NUM_KEYPOINTS*3\n",
    "\n",
    "BASE_LEARNING_RATE = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e029c0b-9b64-467a-bb38-eb66a9e54a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIR = \"datasets/mpii/images_selected/\"\n",
    "JSON = \"datasets/mpii/trainval.json\"\n",
    "\n",
    "\n",
    "with open(JSON) as infile:\n",
    "    json_data = json.load(infile)\n",
    "\n",
    "json_dict = {i[\"image\"]: i for i in json_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674b96c9-96a9-461f-9d63-b776bc5db3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in json_dict.keys():\n",
    "    for i in range(0,16):\n",
    "        json_dict[k]['joints'][i].append(json_dict[k]['joints_vis'][i])\n",
    "    del json_dict[k]['joints_vis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23385e4-99f7-425d-9c53-2fa09f0d3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_aug = iaa.Sequential(\n",
    "    [\n",
    "        iaa.Resize(IMG_SIZE, interpolation=\"linear\"),\n",
    "        iaa.Fliplr(0.3),\n",
    "        iaa.Sometimes(0.3, iaa.Affine(rotate=10, scale=(0.5, 0.7))),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_aug = iaa.Sequential([iaa.Resize(IMG_SIZE, interpolation=\"linear\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e0fd9-a213-4026-ba33-22241f227998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(name):\n",
    "    data = json_dict[name]\n",
    "    img_data = plt.imread(IMG_DIR + data[\"image\"])\n",
    "    # If the image is RGBA convert it to RGB.\n",
    "    # if img_data.shape[-1] == 4:\n",
    "    #     img_data = img_data.astype(np.uint8)\n",
    "    #     img_data = Image.fromarray(img_data)\n",
    "    #     img_data = np.array(img_data.convert(\"RGB\"))\n",
    "    data[\"img_data\"] = img_data\n",
    "    #del img_data\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04eeaf-670d-4281-8b63-55599f3616d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_keypoints(images, keypoints):\n",
    "    fig, axes = plt.subplots(nrows=len(images), ncols=2, figsize=(16, 12))\n",
    "    [ax.axis(\"off\") for ax in np.ravel(axes)]\n",
    "\n",
    "    for (ax_orig, ax_all), image, current_keypoint in zip(axes, images, keypoints):\n",
    "        ax_orig.imshow(image)\n",
    "        ax_all.imshow(image)\n",
    "\n",
    "        if isinstance(current_keypoint, KeypointsOnImage):\n",
    "            for idx, kp in enumerate(current_keypoint.keypoints):\n",
    "                ax_all.scatter(\n",
    "                    [kp.x], [kp.y], c='red', marker=\"v\", s=50, linewidths=2\n",
    "                )\n",
    "        else:\n",
    "            current_keypoint = np.array(current_keypoint)\n",
    "            current_keypoint = current_keypoint[:, :2]\n",
    "            for idx, (x, y) in enumerate(current_keypoint):\n",
    "                ax_all.scatter([x], [y], c='red', marker=\"v\", s=50, linewidths=2)\n",
    "\n",
    "    plt.tight_layout(pad=2.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "samples = list(json_dict.keys())\n",
    "num_samples = 4\n",
    "selected_samples = np.random.choice(samples, num_samples, replace=False)\n",
    "\n",
    "images, keypoints = [], []\n",
    "\n",
    "for sample in selected_samples:\n",
    "    data = get(sample)\n",
    "    image = data[\"img_data\"]\n",
    "    keypoint = data[\"joints\"]\n",
    "\n",
    "    images.append(image)\n",
    "    keypoints.append(keypoint)\n",
    "\n",
    "visualize_keypoints(images, keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e27ec2-fa7d-47e4-8f48-269934227f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyPointsDataset(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, image_keys, aug, batch_size=BATCH_SIZE, train=True):\n",
    "        self.image_keys = image_keys\n",
    "        self.aug = aug\n",
    "        self.batch_size = batch_size\n",
    "        self.train = train\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_keys) // self.batch_size\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.image_keys))\n",
    "        if self.train:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        image_keys_temp = [self.image_keys[k] for k in indexes]\n",
    "        (images, keypoints) = self.__data_generation(image_keys_temp)\n",
    "\n",
    "        return (images, keypoints)\n",
    "\n",
    "    def __data_generation(self, image_keys_temp):\n",
    "        batch_images = np.empty((self.batch_size, IMG_SIZE, IMG_SIZE, 3), dtype=\"int\")\n",
    "        batch_keypoints = np.empty(\n",
    "            (self.batch_size, 1, 1, NUM_KEYPOINTS), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        for i, key in enumerate(image_keys_temp):\n",
    "            \n",
    "            #data = get(key)\n",
    "            \n",
    "            data = json_dict[key]\n",
    "            img_data = plt.imread(IMG_DIR + data[\"image\"])\n",
    "\n",
    "\n",
    "            \n",
    "            \n",
    "            current_keypoint = np.array(data[\"joints\"])[:, :2]\n",
    "            kps = []\n",
    "\n",
    "            for j in range(0, len(current_keypoint)):\n",
    "                kps.append(Keypoint(x=current_keypoint[j][0], y=current_keypoint[j][1]))\n",
    "\n",
    "            kps_obj = KeypointsOnImage(kps, shape=img_data.shape)\n",
    "\n",
    "            (new_image, new_kps_obj) = self.aug(image=img_data, keypoints=kps_obj)\n",
    "            batch_images[i,] = new_image\n",
    "\n",
    "            kp_temp = []\n",
    "            for keypoint in new_kps_obj:\n",
    "                kp_temp.append(np.nan_to_num(keypoint.x))\n",
    "                kp_temp.append(np.nan_to_num(keypoint.y))\n",
    "\n",
    "            batch_keypoints[i,] = np.array(kp_temp).reshape(1, 1, NUM_KEYPOINTS)\n",
    "            del data\n",
    "\n",
    "        batch_keypoints = batch_keypoints / IMG_SIZE\n",
    "\n",
    "\n",
    "        \n",
    "        return (batch_images, batch_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa467fc2-cc19-4485-b197-37126506e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(samples)\n",
    "train_keys, validation_keys = (\n",
    "    samples[int(len(samples) * 0.15) :],\n",
    "    samples[: int(len(samples) * 0.15)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2fc69-88f2-4b16-aa00-c11107feb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeyPointsDataset(train_keys, train_aug)\n",
    "validation_dataset = KeyPointsDataset(validation_keys, test_aug, train=False)\n",
    "\n",
    "print(f\"Total batches in training set: {len(train_dataset)}\")\n",
    "print(f\"Total batches in validation set: {len(validation_dataset)}\")\n",
    "\n",
    "sample_images, sample_keypoints = next(iter(train_dataset))\n",
    "\n",
    "sample_keypoints = sample_keypoints[:4].reshape(-1, 16, 2) * IMG_SIZE\n",
    "visualize_keypoints(sample_images[:4], sample_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da57191-70fd-4361-b305-9a93fd349540",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = tf.keras.applications.MobileNetV3Small(\n",
    "    weights=\"imagenet\", include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4b5224-3d0a-4dc0-bd2e-9fb23fac4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(backbone.layers)-10):\n",
    "#     backbone.layers[i].trainable = False\n",
    "backbone.trainable = False\n",
    "#backbone.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e55f04-0344-4788-a59f-2d9aee76e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "x = tf.keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
    "x = backbone(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.SeparableConv2D(\n",
    "    NUM_KEYPOINTS, kernel_size=5, strides=1, activation=\"relu\"\n",
    ")(x)\n",
    "outputs = tf.keras.layers.SeparableConv2D(\n",
    "    NUM_KEYPOINTS, kernel_size=3, strides=1, activation=\"sigmoid\"\n",
    ")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs, name=\"keypoint_detector\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aac4a4-a0fc-4f86-9d4f-48dba9d3fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "# x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "# x = backbone(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# x = tf.keras.layers.SeparableConv2D(\n",
    "#     NUM_KEYPOINTS, kernel_size=5, strides=1, activation=\"relu\"\n",
    "# )(x)\n",
    "# outputs = tf.keras.layers.SeparableConv2D(\n",
    "#     NUM_KEYPOINTS, kernel_size=3, strides=1, activation=\"sigmoid\"\n",
    "# )(x)\n",
    "\n",
    "# model = tf.keras.Model(inputs, outputs, name=\"keypoint_detector\")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f5fde-f164-4357-b56a-d73af80d1482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "# x = tf.keras.applications.resnet.preprocess_input(inputs)\n",
    "# x = backbone(x)\n",
    "\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# NEURONS = 1000\n",
    "# x = tf.keras.layers.Dense(NEURONS, activation='relu')(x)\n",
    "# outputs = tf.keras.layers.Dense(NUM_KEYPOINTS, activation = 'softmax')(x)\n",
    "\n",
    "\n",
    "# model = tf.keras.Model(inputs, outputs, name=\"keypoint_detector\")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dcedef-314e-4f77-92c0-0da94ceeaa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = tf.keras.layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "# x = tf.keras.applications.mobilenet_v3.preprocess_input(inputs)\n",
    "# x = backbone(x)\n",
    "# x = tf.keras.layers.Dropout(0.2)(x)\n",
    "# x = tf.keras.layers.SeparableConv2D(\n",
    "#     576, kernel_size=5, strides=1, activation=\"relu\"\n",
    "# )(x)\n",
    "# x = tf.keras.layers.SeparableConv2D(\n",
    "#     576, kernel_size=3, strides=1, activation=\"sigmoid\"\n",
    "# )(x)\n",
    "# x = tf.keras.layers.Flatten()(x)\n",
    "# x = tf.keras.layers.Dense(NUM_KEYPOINTS, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.3)(x)\n",
    "# x = tf.keras.layers.Dense(NUM_KEYPOINTS, activation='relu')(x)\n",
    "# x = tf.keras.layers.Dropout(0.3)(x)\n",
    "# outputs = tf.keras.layers.Dense(NUM_KEYPOINTS, activation='softmax')(x)\n",
    "\n",
    "# model = tf.keras.Model(inputs, outputs, name=\"keypoint_detector\")\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fdbbee-8816-41b9-a061-49a118663107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(BASE_LEARNING_RATE),metrics=['accuracy'], run_eagerly=True)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(BASE_LEARNING_RATE), loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()], run_eagerly=True)\n",
    "# model.compile(optimizer='adam', loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()])#, run_eagerly=True)\n",
    "# model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(BASE_LEARNING_RATE),metrics=['mae'], run_eagerly=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(BASE_LEARNING_RATE), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbb291c-4d89-4b83-a7f3-8b586073aba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p training_ckp\n",
    "checkpoint_path = \"training_ckp/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "SAVE_PERIOD = 10\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, \n",
    "                                                    verbose=1, \n",
    "                                                    save_weights_only=True,\n",
    "                                                    save_freq='epoch',\n",
    "                                                    #save_freq=int(SAVE_PERIOD * STEPS_PER_EPOCH),\n",
    "                                                )\n",
    "\n",
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(monitor =\"val_loss\", mode =\"min\", patience = 20\n",
    "                                                          , restore_best_weights = True)\n",
    "\n",
    "!mkdir -p training_logs\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=\"training_logs/{}\".format(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5351cd99-533b-44ee-9cda-d2479ddb7d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[\n",
    "                                cp_callback,\n",
    "                                earlystopping_callback,\n",
    "                                tensorboard\n",
    "                              ]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8f3bec-72ea-4186-9fe1-2c3a6f11e5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/before_finetuning_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468e1aa-70c2-4c21-925a-83cc6d669d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in backbone.layers:\n",
    "    layer.trainable = True\n",
    "# backbone.trainable = True\n",
    "\n",
    "\n",
    "print(\"Number of layers in the base model: \", len(backbone.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e92f39f-b334-4f7d-8e40-4dbb33f849f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e160c-bfe8-4e07-93cb-828b503b4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_tune_at = len(backbone.layers)-10\n",
    "\n",
    "# for layer in backbone.layers[:fine_tune_at]:\n",
    "#     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1404a204-7025-4d7d-b931-7f335d0cb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dd83c5-d1c0-4fd3-816a-78b2f42a5c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "#               optimizer = tf.keras.optimizers.Adam(BASE_LEARNING_RATE/10),\n",
    "#               metrics=['accuracy'])\n",
    "# model.compile(loss=\"mse\", optimizer=tf.keras.optimizers.Adam(BASE_LEARNING_RATE/10),metrics=['accuracy'], run_eagerly=True)\n",
    "#model.compile(optimizer=tf.keras.optimizers.Adam(BASE_LEARNING_RATE/10), loss='mean_squared_error', metrics=['mae'], run_eagerly=True)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(BASE_LEARNING_RATE/10), loss='mean_squared_error', metrics=[tf.keras.metrics.RootMeanSquaredError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf0fed-e128-4227-b69c-c9b2a40b645d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add checkpoints\n",
    "!mkdir -p finetuning_ckp\n",
    "checkpoint_path = \"finetuning_ckp/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create a callback that saves the model's weights\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                                                    filepath=checkpoint_path, \n",
    "                                                    verbose=1, \n",
    "                                                    save_weights_only=True,\n",
    "                                                    save_freq='epoch',\n",
    "                                                    period=5\n",
    "                                                    )\n",
    "\n",
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(monitor =\"val_loss\", mode =\"min\", patience = 20, restore_best_weights = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a536a-35d6-4126-a31f-ba26d5304580",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINETUNE_EPOCHS = 20\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=FINETUNE_EPOCHS,\n",
    "                         validation_data=validation_dataset,\n",
    "                         callbacks=[\n",
    "                                cp_callback,\n",
    "                                earlystopping_callback,\n",
    "                                tensorboard\n",
    "                              ]\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fa2c1-1cea-4240-b7f6-6bcd2aa16a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model/final_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
